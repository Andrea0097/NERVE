# -*- coding: utf-8 -*-
"""nerve.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1x6NeJRSeHicm8NoyhTr-bAYm0b3CJq02

# NERVE

## Intro: install the dependencies and set the parameters.
Please manage to upload your proteome(s) first.
"""

# Commented out IPython magic to ensure Python compatibility.
# # %%capture is to hide the output
# #@title Installation of the dependencies { display-mode: "form" }
# %%capture
# import subprocess # first of all, to use bash commands and import / git / install all the dependencies
# 
# # we can check the errors through this method instead of using bash commands
# 
# def bashCmdMethod(bashCmd):
#     process = subprocess.Popen(bashCmd.split(), stdout=subprocess.PIPE)
#     output, error = process.communicate()
#     return output, error
# 
# bashCmdMethod("rm -r spaan")
# bashCmdMethod("rm -r iFeature")
# bashCmdMethod("rm -r NERVE")
# 
# bashCmdMethod("git clone https://github.com/Superzchen/iFeature")
# bashCmdMethod("git clone https://github.com/nicolagulmini/spaan")
# bashCmdMethod("git clone https://github.com/nicolagulmini/NERVE")
# bashCmdMethod("python -m pip install git+https://github.com/nicolagulmini/tmhmm.py")
# bashCmdMethod("pip install Bio")
# bashCmdMethod("pip install pycurl")
# bashCmdMethod("pip install Pandas")
# 
# bashCmdMethod("apt-get install ncbi-blast+") # for the autoimmunity module if we meant to use blastp to make the comparisons
# 
# ### setup deepfri evnironment for function module:
# bashCmdMethod("git clone https://github.com/flatironinstitute/DeepFRI.git DeepFri") # get github repo
# bashCmdMethod("python3 ./DeepFri/setup.py install") # install dependencies
# bashCmdMethod("wget https://users.flatironinstitute.org/vgligorijevic/public_www/DeepFRI_data/newest_trained_models.tar.gz") # download models
# bashCmdMethod("tar xvzf newest_trained_models.tar.gz") # unzip models folder and move it to DeepFri directory
# bashCmdMethod("mv trained_models ./DeepFri/trained_models")
# bashCmdMethod("rm newest_trained_models.tar.gz")
# bashCmdMethod("git clone https://francesco1997:2At9n1feaZ7a_Dy5NFRQ@gitlab.com/francesco1997/shared-files.git") # import and move github files
# bashCmdMethod("cp ./shared-files/function.py ./function.py")

#@title Import { display-mode: "form" }
import tmhmm                                                # to predict transmembrane domains
from Bio import SeqIO, pairwise2                            # to handle .fasta files and to align sequences
from Bio.Blast.Applications import NcbiblastpCommandline    # autoimmunity module, to query the local sapiens database
from Bio.ExPASy.ScanProsite import scan, read               # scan prosite functional domains information
from Bio.Blast import NCBIXML                               # to parse the peptides
from NERVE import Protein                                   # to contain proteins information
from NERVE.cello_scraper import *
import numpy as np                                          # to handle vectors and matrices (machine / deep learning modules)
import tensorflow                                           # for deep learning modules
from tensorflow import keras                                # to use the spaan model (to predict the probability of a protein to be an adhesin)
import pandas                                               # to read mhcpep.csv and write the final report
from spaan.data_processing import *                         # to extract proteins features for the spaan model
import sys
import urllib
import os
from shutil import rmtree
from time import sleep
import ipywidgets as widgets                                # to make interactive prints
from IPython.display import display

#@title Parameters { display-mode: "form" }

p_ad_no_citoplasm_filter = 0.46 #@param {type:"number"}     # default 0.46
p_ad_extracellular_filter = 0.38 #@param {type:"number"}    # default 0.38
transmemb_doms_limit = 3 #@param {type:"integer"}           # default 3
sapiens_peptides_sum_limit = .15 #@param {type:"number"}    # default 0.15
mouse_peptides_sum_limit = .15 #@param {type:"number"}    # default 0.15

razor_len = 50 #@param {type:"integer"}                     # default 50
e_value = 1e-10 #@param {type:"number"}                     # default 1e-10
minlength = 9 #@param {type:"integer"}                      # default 9
substitution = 3 #@param {type:"integer"}                   # default 3
mismatch = 1 #@param {type:"integer"}                       # default 1
path_to_another_proteome = None  
similarity_function = 0.8 #@param {type:"number"}           # default 0.8
virlimit = 0.50 #@param {type:"number"}                     # default 0.5
padlimit = 0.85 #@param {type:"number"}                     # default 0.85

#@markdown ---
#@markdown ### Enter a verbose. 
#@markdown 0 means no prints, 1 only the necessary, 2 prints out everything (be careful with huge proteomes):
verbose = 1 #@param {type:"slider", min:0, max:2, step:1}

#@markdown ---

#@markdown ### Enter the graam of the bacteria
GRAM = "n" #@param ["p", "n"] 

psortb_output_path = None 

# for now put here, then we can decide if it is more convenient to move these options near the relative modules
#@markdown ---

#@markdown ### Choose which modules you want to activate
razor = True #@param {type:"boolean"}
mouse = True #@param {type:"boolean"}
virulent = False #@param {type:"boolean"}
select = True #@param {type:"boolean"}
annotation = True #@param {type:"boolean"}

#@title Insert name of the input files { display-mode: "form" }

name_input_fasta = "tre" #@param {type:"string"}
another_proteome = False #@param {type:"boolean"}

path_to_fastas = "./NERVE/test_data_input/" + name_input_fasta + ".fasta" # for now
if another_proteome:
	name_other_proteome_fasta = "tmp" #@param {type:"string"}
	path_to_another_proteome = "./NERVE/test_data_input/"+name_other_proteome_fasta+".fasta"
list_of_fasta_proteins = list(SeqIO.parse(path_to_fastas, "fasta")) # put the right path

list_of_proteins = []
for p in list_of_fasta_proteins:
	p_id = p.id
	p_seq = p.seq
	list_of_proteins.append(Protein.Protein(p_id, p_seq))

if verbose == 2:
	for p in list_of_proteins:
		p.print_information()
		print()

# check strange symbols in proteins

# show proteome information even if verbose is not 2

if verbose < 2:
	button = widgets.Button(description="show proteome information")
	output = widgets.Output()

	def on_button_clicked(b): # Display the message within the output widget.
		with output:
			print()
			for p in list_of_proteins:
				p.print_information()
				print()

	button.on_click(on_button_clicked)
	display(button, output)

"""# Subcelloc (da sistemare)

Predict the subcellular localization of your pathogen's proteins using CELLO predictor.
"""

# run cello pred
cello_text_output = cello_scraper(GRAM, path_to_fastas)
cello_output_parser(cello_text_output)

#da aggiungere

# prendere la funzione dall'output e inserirla nell'oggetto protein 
# for p in list_of_proteins:
    # check if the protein corresponds 
    # tipo if p.sequence == output.sequence or p.name == output.name
    # p.localization = annotation

"""# Adhesin 

Predict the probability to be an adhesin protein with ESPAAN.
"""

#@title { display-mode: "form" }
if verbose > 0: print("Adhesin start...")

# take the model from nerve but the methods from spaan, cause the model in spaan could be modified and tested
model = keras.models.load_model('./NERVE/espaan_model.h5') 

for p in list_of_proteins:
	p.p_ad = float(model.predict([
			     np.array([aminoacids_frequencies(p.sequence)]),
			     np.array([multiplet_frequencies(p.sequence, 3)]),
			     np.array([multiplet_frequencies(p.sequence, 4)]),
			     np.array([multiplet_frequencies(p.sequence, 5)]),
			     np.array([dipeptide_frequencies(p.sequence)]),
			     np.array([charge_composition(p.sequence)]),
			     np.array([hydrophobic_composition(p.sequence)])
		     ]))

if verbose > 0: print("Done.")

if verbose == 2:
	print()
	for p in list_of_proteins:
		p.print_information()
		print()
# show proteome information even if verbose is not 2
if verbose < 2:
	button = widgets.Button(description="show proteome information")
	output = widgets.Output()
	button.on_click(on_button_clicked)
	display(button, output)

"""# Tmhelices

Predict the topology of your pathogen's proteins, in particular considering the number of transmembrane domains.
"""

#@title { display-mode: "form" }
if verbose > 0: print("Tmhelices start...")

for p in list_of_proteins:
    annotation, _ = tmhmm.predict(p.sequence)
    p.tmhmm_seq = annotation
    transmembrane_domains = 0
    for i in range(len(annotation)-1):
        if (annotation[i] == 'i' or annotation[i] == 'o') and annotation[i+1] == 'M':
            transmembrane_domains += 1
    p.transmembrane_doms = transmembrane_domains

if verbose > 0: print("Done.")

if verbose == 2:
    print()
    for p in list_of_proteins:
        p.print_information()
        print()

if verbose < 2:
	button = widgets.Button(description="show proteome information")
	output = widgets.Output()
	button.on_click(on_button_clicked)
	display(button, output)

"""# Razor

Consider only the proteins with at least 3 transmembrane domains. 
For outermembrane proteins consider both the 'i' and 'o' loops, otherwise only the 'o' loop. 
Take the longest out-membrane piece and replace the original sequence with it to perform the following analyses
(only if the longest piece is reasonably long../ minimum 50 aa length)
"""

#@title { display-mode: "form" }
if razor:

    if verbose > 0:
        print("Loop-razor start...")
        print("Warning: razor uses X as an exclusive symbol to split the final protein. Check if X is used inside the protein sequence!")

    for p in list_of_proteins:
        if p.transmembrane_doms >= transmemb_doms_limit:
            longest_loop = max(p.provide_raw_loops(), key = lambda k: len(k))
            if len(longest_loop) > razor_len:
                if verbose > 0: print("Substituting " + str(p.id) + " sequence with its longest loop.")
                p.original_sequence_if_razor = p.sequence
                p.sequence = longest_loop 

    if verbose > 0: print("Done.") 

    if verbose == 2:
        print()
        for p in list_of_proteins:
            p.print_information()
            print()
    # show proteome information even if verbose is not 2
    if verbose < 2:
        button = widgets.Button(description="show proteome information")
        output = widgets.Output()
        button.on_click(on_button_clicked)
        display(button, output)

"""# Autoimmunity 

Compare your pathogen's proteome with human proteome using BLASTp.Then, similar shared sequences are scanned in order to find MHC-I and MHC-II ligands. This is useful to help avoid possible autoimmunity reactions.
"""

#@title { display-mode: "form" }
if verbose > 0: print("Autoimmunity start...")
blastx_cline = NcbiblastpCommandline(query=path_to_fastas, db="./NERVE/sapiens_database/sapiens", evalue=e_value, outfmt=5, out="./sapiens.xml") # 5 is for xml 
stdout, stderr = blastx_cline()
if verbose > 0: print("Warning: you can find a sapiens.xml file on your working directory which is the outputs of the autoimmunity module.\nDo not delete during the computation!\nAfter the computation it will be deleted in order to avoid future collisions.")

# for each result in the .xml file...
for record in NCBIXML.parse(open("./sapiens.xml")):
    query_name = record.query.split(' ')[0] # take only the query id 
    # take the right candidate to update
    tmp_protein = list_of_proteins[0]
    for p in list_of_proteins:
        if p.id == query_name:
            tmp_protein = p
    # for each effective alignment between the tmp candidate and the human proteome
    for alignment in record.alignments:
        for hsp in alignment.hsps: # collect all the interesting peptides
            #print(hsp.query, hsp.query_start, hsp.match)
            tmp_protein.list_of_shared_human_peps += Protein.Protein.hsp_match_parser(hsp.match, hsp.query, parsing_window_size=minlength, max_sub=substitution, max_mismatch=mismatch )

    # print out the peptides (if there are any)
    if verbose > 0:
        sys.stdout.write('\r')
        if len(tmp_protein.list_of_shared_human_peps) == 0:
            sys.stdout.write("\nNo interesting peptides for " + query_name)
            sys.stdout.flush()
            sleep(0.25)
        else:
            sys.stdout.write("\nList of interesting peptides for " + query_name + ": " + str([el['match'] for el in tmp_protein.list_of_shared_human_peps]))
            sys.stdout.flush()
            sleep(3)
os.remove("./sapiens.xml") # delete after the computation

# sum peptides
for p in list_of_proteins:
		score = 0
		if len(p.list_of_shared_human_peps) > 0:
			prev_match = p.list_of_shared_human_peps[0]['match']
			score = len(prev_match)
			for pept in p.list_of_shared_human_peps[1:]:
				tmp_match = pept['match']
				if tmp_match[:len(tmp_match)-1] == prev_match[1:]:
					score += 1
				else:
					score += len(tmp_match)
				prev_match = tmp_match
		p.sapiens_peptides_sum = score/p.length

mhcpep = pandas.read_csv("./NERVE/mhcpep/mhcpep_sapiens.csv", skipinitialspace=True)
number_of_proteins = len(list_of_proteins)
loading = 0
for p in list_of_proteins:
    # to print only one line
    if verbose > 0:
        sys.stdout.write('\r')
        sys.stdout.write("Check the protein " + str(p.id) + "Number " + str(loading) + "/" + str(number_of_proteins))
        sys.stdout.flush()
        sleep(0.25)
    for seq in p.list_of_shared_human_peps:
        for pep in mhcpep['Epitope.2']:
            tmp_matches = Protein.Protein.peptide_comparison(seq, pep)
            p.list_of_peptides_from_comparison_with_mhcpep_sapiens += tmp_matches
    loading += 1

if verbose > 0: print("\nDone.")

if verbose == 2:
    print()
    for p in list_of_proteins:
        p.print_information()
        print()

if verbose < 2:
	button = widgets.Button(description="show proteome information")
	output = widgets.Output()
	button.on_click(on_button_clicked)
	display(button, output)

"""# Mouse immunity
Compare your pathogen's proteome with mouse proteome using BLASTp.Then, similar shared sequences are scanned in order to find MHC mouse ligands. This is useful to help avoid possible autoimmunity reactions in mice.
"""

#@title { display-mode: "form" }
if mouse:
    if verbose > 0: print("Mouse immunity start...")
    blastx_cline = NcbiblastpCommandline(query=path_to_fastas, db="./NERVE/mouse_database/mouse", evalue=e_value, outfmt=5, out="./mouse.xml")
    stdout, stderr = blastx_cline()
    if verbose > 0: print("Warning: you can find a mouse.xml file on your working directory which is the outputs of the autoimmunity module. Do not delete during the computation. After the computation it will be deleted in order to avoid future collisions.")

    for record in NCBIXML.parse(open("./mouse.xml")):
        query_name = record.query.split(' ')[0]
        tmp_protein = list_of_proteins[0]
        for p in list_of_proteins:
            if p.id == query_name:
                tmp_protein = p

        for alignment in record.alignments:
            for hsp in alignment.hsps:
                tmp_protein.list_of_shared_mouse_peps += Protein.Protein.hsp_match_parser(hsp.match, hsp.query, parsing_window_size=minlength, max_sub=substitution, max_mismatch=mismatch )

        if verbose > 0:
            sys.stdout.write('\r')
            if len(tmp_protein.list_of_shared_mouse_peps) == 0:
                sys.stdout.write("No interesting peptides for " + query_name)
                sys.stdout.flush()
                sleep(0.25)
            else:
                sys.stdout.write("List of interesting peptides for " + query_name + ": " + str([el['match'] for el in tmp_protein.list_of_shared_mouse_peps]))
                sys.stdout.flush()
                sleep(3)
    os.remove("./mouse.xml") # delete after the computation
    
    mhcpep = pandas.read_csv("./NERVE/mhcpep/mhcpep_mouse.csv", skipinitialspace=True)
    number_of_proteins = len(list_of_proteins)
    loading = 0
    for p in list_of_proteins:
        if verbose > 0:
            sys.stdout.write('\r')
            sys.stdout.write("Check the protein " + str(p.id) + "Number " + str(loading) + "/" + str(number_of_proteins))
            sys.stdout.flush()
            sleep(0.25)
        for seq in p.list_of_shared_mouse_peps:
            for pep in mhcpep['Epitope.2']:
                tmp_matches = Protein.Protein.peptide_comparison(seq, pep)
                p.list_of_peptides_from_comparison_with_mhcpep_mouse += tmp_matches
        loading += 1

    # sum peptides
    for p in list_of_proteins:
        score = 0
        if len(p.list_of_shared_mouse_peps) > 0:
            prev_match = p.list_of_shared_mouse_peps[0]['match']
            score = len(prev_match)
            for pept in p.list_of_shared_mouse_peps[1:]:
                tmp_match = pept['match']
                if tmp_match[:len(tmp_match)-1] == prev_match[1:]:
                    score += 1
                else:
                    score += len(tmp_match)
                prev_match = tmp_match
        p.mouse_peptides_sum = score/p.length
        
    if verbose > 0: print("\nDone.")

    if verbose == 2:
        print()
        for p in list_of_proteins:
            p.print_information()
            print()

    if verbose < 2:
        button = widgets.Button(description="show proteome information")
        output = widgets.Output()
        button.on_click(on_button_clicked)
        display(button, output)

"""# Conservation

Compare your pathogen's proteome with another one from a different serogroup/strain, using BLASTp. The more the  protein sequences are conserved between strains, the more protective the vaccine results.


"""

#@title { display-mode: "form" }
if path_to_another_proteome is not None:
    if verbose > 0: print("Conservation start...")
    bashCmd = "makeblastdb -in " + path_to_another_proteome + " -dbtype prot -parse_seqids -out ./compare_proteome/compare_proteome"
    process = subprocess.Popen(bashCmd.split(), stdout=subprocess.PIPE)
    output, error = process.communicate()
    
    blastx_cline = NcbiblastpCommandline(query=path_to_fastas, db="./compare_proteome/compare_proteome", evalue=e_value, outfmt=5, out="./comparison.xml") # 5 is for xml 
    stdout, stderr = blastx_cline()
    
    for record in NCBIXML.parse(open("./comparison.xml")):
        query_name = record.query.split(' ')[0] 
    
        tmp_protein = list_of_proteins[0]
        for p in list_of_proteins:
            if p.id == query_name:
                tmp_protein = p
                #max_score = 0
        for alignment in record.alignments:
            for hsp in alignment.hsps:
                #if hsp.score > max_score: max_score = hsp.score
                tmp_protein.list_of_shared_conserv_proteome_peps += Protein.Protein.hsp_match_parser(hsp.match, hsp.query, parsing_window_size=minlength, max_sub=substitution, max_mismatch=mismatch)
    		           
    # sum peptides
    for p in list_of_proteins:
		    score = 0
		    if len(p.list_of_shared_conserv_proteome_peps) > 0:
		        prev_match = p.list_of_shared_conserv_proteome_peps[0]['match']
		        score = len(prev_match)
		        for pept in p.list_of_shared_conserv_proteome_peps[1:]:
		            tmp_match = pept['match']
		            if tmp_match[:len(tmp_match)-1] == prev_match[1:]:
		                score += 1
		            else:
		                score += len(tmp_match)
		            prev_match = tmp_match
		    p.conservation_score = score/p.length

    os.remove("./comparison.xml") # delete after the computation
    if os.path.isdir("compare_proteome"):
        rmtree("compare_proteome")
		
    if verbose > 0: print("\nDone.")

    if verbose == 2:
        print()
        for p in list_of_proteins:
            p.print_information()
            print()

    if verbose < 2:
        button = widgets.Button(description="show proteome information")
        output = widgets.Output()
        button.on_click(on_button_clicked)
        display(button, output)

"""# Virulence

Predict the probability to be considered as a virulence factor, only analyzing your pathogen protein sequences.
"""

#@title { display-mode: "form" }
if verbose > 0: print("Virulence start...")

if virulent:
	bashCmdMethod("python3 iFeature/iFeature.py --file " + path_to_fastas + " --type AAC --out aac.out")
	bashCmdMethod("python3 iFeature/iFeature.py --file " + path_to_fastas + " --type DPC --out dpc.out")
	bashCmdMethod("python3 iFeature/iFeature.py --file " + path_to_fastas + " --type CTDC --out ctdc.out")
	bashCmdMethod("python3 iFeature/iFeature.py --file " + path_to_fastas + " --type CTDT --out ctdt.out")
	bashCmdMethod("python3 iFeature/iFeature.py --file " + path_to_fastas + " --type CTDD --out ctdd.out")

	extension = ".out"
	files = ["aac", "dpc", "ctdc", "ctdt", "ctdd"]
	datasets = [[] for el in files]
	for i in range(len(files)):
		with open('./'+files[i]+extension) as f:
			lines = f.readlines()[1:]
			check_prot = 0
			for line in lines:
				information = line.split('\t')
				if not information[0] == list_of_proteins[check_prot].id:
					print("Error in protein order! Return")
				datasets[i].append(np.array([float(el) for el in information[1:]]))
				check_prot += 1
		datasets[i] = np.array(datasets[i])
		
	labels = np.array([0. for _ in range(len(datasets[0]))])
	virulent_model = tensorflow.keras.models.load_model('./NERVE/virulent_classification_model.h5')
	for i in range(len(datasets)):
		for j in range(len(datasets[i])):
			datasets[i][j] = np.array(datasets[i][j])
		datasets[i] = np.array(datasets[i])
	prediction = virulent_model.predict(datasets)
	for i in range(len(prediction)):
		list_of_proteins[i].p_vir = prediction[i][0]

	for file in files:
		os.remove("./"+file+extension) # delete after the computation

	if verbose > 0: print("Done.")

	if verbose == 2:
		print()
		for p in list_of_proteins:
			p.print_information()
			print()
	if verbose < 2:
		button = widgets.Button(description="show proteome information")
		output = widgets.Output()
		button.on_click(on_button_clicked)
		display(button, output)

"""# Annotation (da sistemare)

Functionally annotate your pathogen protein sequences retrieving info from Uniprot KB or using DeepFRI predictor, which assigns a GO term to each protein.
"""

# run function.py with its argument
if annotation:
    if verbose > 0: print("Annotation start...")
    subprocess.call(["python3", "function.py", "-path_to_fastas", path_to_fastas])

    if verbose > 0: print("Done.")

    if verbose == 2:
        print()
        for p in list_of_proteins:
            p.print_information()
            print()
    if verbose < 2:
        button = widgets.Button(description="show proteome information")
        output = widgets.Output()
        button.on_click(on_button_clicked)
        display(button, output)

"""# Select

Filters the best VCs (vaccine candidates) from your pathogen proteome.
"""

#@title { display-mode: "form" }

if select:
	if verbose > 0: print("Select start...")
	final_list = []
	
	for protein in list_of_proteins:
		if protein.localization == "Cytoplasmic": continue 
		if protein.p_ad < p_ad_no_citoplasm_filter and not protein.localization == "Extracellular": continue 
		if protein.p_ad < p_ad_extracellular_filter and protein.localization == "Extracellular": continue 
		if (protein.transmembrane_doms >= transmemb_doms_limit) and (protein.original_sequence_if_razor is None): continue
		if protein.sapiens_peptides_sum > sapiens_peptides_sum_limit: continue
		if len(protein.list_of_peptides_from_comparison_with_mhcpep_sapiens) >= 1: continue
		if (protein.localization == "Unknown") and (protein.p_ad < padlimit): continue
		if mouse:
			if protein.mouse_peptides_sum > mouse_peptides_sum_limit: continue 
			if len(protein.list_of_peptides_from_comparison_with_mhcpep_mouse) >= 1: continue 
		if virulent:
			if protein.p_vir < virlimit: continue
		final_list.append(protein)
	
else: final_list = list_of_proteins

if path_to_another_proteome is not None: final_list.sort(key=lambda p: p.conservation_score, reverse=True) # ranking
Protein.Protein.information_to_csv(list_of_proteins)

if verbose > 0: print("Done. Please find the results in output.csv file.")

if verbose == 2:
	print()
	for p in list_of_proteins:
		p.print_information()
		print()
if verbose < 2:
	button = widgets.Button(description="show proteome information")
	output = widgets.Output()
	button.on_click(on_button_clicked)
	display(button, output)

